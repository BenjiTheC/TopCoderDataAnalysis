{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KNN for pricing model prediction\n",
    "    X: doc-vec appending metadata\n",
    "    y: prize\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tc_main import TopCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topcoder = TopCoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the subtrack `code`: get rid of extreme prize - prize too high can be mis-labeled.\n",
    "- the subtrack `first-2-finish`: get rid of extreme prize above 1000\n",
    "\n",
    "Handpick a F2F task - that is overprized can be mislabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "knn_measures = {}\n",
    "\n",
    "for i in range(3):\n",
    "    with open(os.path.join(os.curdir, 'pricing_model_3', f'knn_pricing_model_measure_{i}.json')) as f:\n",
    "        knn_measure_dct = {track: {int(dimension): result['Mean_MRE'] for dimension, result in d.items()} for track, d in json.load(f).items()}\n",
    "        \n",
    "        knn_measures[i] = pd.DataFrame([dict(track=track, dimension=dimension, model=i, mmre=mmre) for track, d in knn_measure_dct.items() for dimension, mmre in d.items()])\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean the price that are too high - only prize < 5000\n",
    "\n",
    "- **BERT to detect contect representation.** \n",
    "- LSTM - softmax\n",
    "  - fit the context by group of challenges / project of challenges | size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_type = ['all', 'subtrack', 'number_of_platform', 'number_of_technologies', 'challenge_duration']\n",
    "\n",
    "knn_measure_lst = []\n",
    "for model in range(5):\n",
    "    with open(os.path.join(os.curdir, 'pricing_model_3', f'knn_pricing_model_measure_{model}.json')) as f:\n",
    "        mmre_by_dim = json.load(f)['develop']\n",
    "        knn_measure_lst.extend([dict(dimension=dim, mmre=mmre, meta_data=meta_data_type[model]) for dim, mmre in mmre_by_dim.items()])\n",
    "\n",
    "knn_measure_df = pd.DataFrame(knn_measure_lst)\n",
    "        \n",
    "pm0_dev_measure_dfs = {}\n",
    "for dimension in range(100, 1100, 100):\n",
    "    with open(os.path.join(os.curdir, f'pricing_model_0', 'develop_track', 'measures', f'measure_{dimension}D.json')) as f:\n",
    "        pm0_dev_measure_dfs[dimension] = pd.read_json(f, orient='records').set_index('index')\n",
    "\n",
    "pm0_mmre = [dict(dimension=dimension, mmre=df['MRE'].mean()) for dimension, df in pm0_dev_measure_dfs.items()]\n",
    "pm0_mmre_df = pd.DataFrame(pm0_mmre)\n",
    "pm0_mmre_df['meta_data'] = ['pricing_model_0'] * len(pm0_mmre_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([knn_measure_df, pm0_mmre_df]).reset_index(drop=True).astype({'dimension': int, 'mmre': float, 'meta_data': str}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(10, 5), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=pd.concat([knn_measure_df, pm0_mmre_df]).reset_index(drop=True).astype({'dimension': int, 'mmre': float, 'meta_data': str}),\n",
    "        x='dimension',\n",
    "        y='mmre',\n",
    "        hue='meta_data',\n",
    "        size='meta_data',\n",
    "        sizes=[2.75, 0.75, 0.75, 0.75, 0.75, 2.75],\n",
    "        marker='o',\n",
    "        markersize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, prop={'size': 8})\n",
    "    \n",
    "    ax.set_xticks(list(range(100, 1100, 100)))\n",
    "    ax.set_xticklabels(labels=list(range(100, 1100, 100)))\n",
    "    \n",
    "    ax.set_xlabel('Dimension')\n",
    "    ax.set_ylabel('Mean MRE')\n",
    "    ax.set_title('Pricing model 3 result - DEVELOP track')\n",
    "    \n",
    "#     fig.savefig(os.path.join(os.pardir, os.pardir, 'presentation', 'presentation1', 'pm_models3_result.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Analysis)",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
