{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pricing Models 0, 1, 2, 3 Measurement\n",
    "\n",
    "Besides the first pricing model (`pricing_model_0`) that train word2vec with full corpus and find 10 most similar challenge and taken average of their prizes as estimate. I've build 3 more pricing models:\n",
    "\n",
    "1. Training word2vec model with **_corpus that deletes overlap sections_**, then find 10 most similar challenge and take average of their prizes as estimate\n",
    "2. Training word2vec model with **_corpus that detects phrases (more than one word)_**, then find 10 most similar challenge and take average of their prizes as estimate\n",
    "3. Training K-Near Neighboors model with:\n",
    "   - X: document vectors calculated from pricing_model_0 appending meta data of challenges\n",
    "   - y: actual total prize\n",
    "\n",
    "Here below I will demonstrate the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tc_main import TopCoder\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "MODELS = (0, 1, 2)\n",
    "TRACKS = ('all', 'develop', 'design')\n",
    "DIMENSIONS = range(100, 1100, 100)\n",
    "\n",
    "topcoder = TopCoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_measure_dfs = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for model in MODELS:\n",
    "    for track in TRACKS:\n",
    "        for dimension in DIMENSIONS:\n",
    "            with open(os.path.join(os.curdir, f'pricing_model_{model}', f'{track}_track', 'measures', f'measure_{dimension}D.json')) as f:\n",
    "                pm_measure_dfs[model][track][dimension] = pd.read_json(f, orient='records').set_index('index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMRE = []\n",
    "for model in MODELS:\n",
    "    for track in TRACKS:\n",
    "        for dimension in DIMENSIONS:\n",
    "            MMRE.append(dict(track=track, dimension=dimension, model=model, mmre=pm_measure_dfs[model][track][dimension]['MRE'].mean()))\n",
    "\n",
    "mmre_df = pd.DataFrame(MMRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean MRE by track and dimension is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = [\n",
    "    'Word2Vec from Full corpus',\n",
    "    'Word2Vec from No Overlap corpus',\n",
    "    'Word2Vec from phrases detected corpus',\n",
    "    'Word2Vec from Full corpus - median'\n",
    "]\n",
    "\n",
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(len(MODELS), 1, figsize=(9, 3 * len(MODELS)), dpi=200)\n",
    "\n",
    "    for i, model in enumerate(MODELS):\n",
    "        ax = axes[i]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=mmre_df.loc[mmre_df.model == model],\n",
    "            x='dimension',\n",
    "            y='mmre',\n",
    "            hue='track',\n",
    "            style='track',\n",
    "            palette='deep',\n",
    "            linewidth=0.618,\n",
    "            markers=['o', 'o', 'o'],\n",
    "            markersize=4,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, prop={'size': 8})\n",
    "\n",
    "        ax.set_xticks(list(range(100, 1100, 100)))\n",
    "        ax.set_xticklabels(labels=list(range(100, 1100, 100)))\n",
    "        ax.set_ylim(top=7, bottom=0)\n",
    "        ax.set_yticks(list(range(7)))\n",
    "        ax.set_yticklabels(labels=list(range(7)))\n",
    "\n",
    "        ax.set_xlabel('Dimensionality of document vectors')\n",
    "        ax.set_ylabel('Mean MRE')\n",
    "        ax.set_title(f'Pricing model {model} - {title_text[i]}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('img/pm012_results.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpectedly, with the removal of overlap sections and phrases detected. **The accuracy of the pricing models decrease.**\n",
    "\n",
    "This result is against the assumption I made that with the refinement of the input corpus, the accuracy will increase.\n",
    "\n",
    "> Note: All three models have removed the stop words from the cropus\n",
    "\n",
    "To better demo the decreasement of models. I plot the MREs by track in different model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(9, 9), dpi=200)\n",
    "\n",
    "    for idx, track in enumerate(TRACKS):\n",
    "        ax = axes[idx]\n",
    "        sns.lineplot(\n",
    "            data=mmre_df.loc[mmre_df.track == track],\n",
    "            x='dimension',\n",
    "            y='mmre',\n",
    "            hue='model',\n",
    "            style='model',\n",
    "            palette='deep',\n",
    "            linewidth=0.618,\n",
    "            markers=['o'] * len(MODELS),\n",
    "            markersize=4,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, prop={'size': 8})\n",
    "\n",
    "        ax.set_xticks(list(range(100, 1100, 100)))\n",
    "        ax.set_xticklabels(labels=list(range(100, 1100, 100)))\n",
    "        # ax.set_ylim(top=7, bottom=0)\n",
    "        # ax.set_yticks(list(range(7)))\n",
    "        # ax.set_yticklabels(labels=list(range(7)))\n",
    "\n",
    "        ax.set_xlabel('Dimensionality of document vectors')\n",
    "        ax.set_ylabel('Mean MRE')\n",
    "        ax.set_title(f'Pricing model MMRE - {track.upper()} track')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('img/pm012_results_comparison.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 4), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=mmre_df.loc[(mmre_df.track == 'develop') & (mmre_df.model != 3)],\n",
    "        x='dimension',\n",
    "        y='mmre',\n",
    "        hue='model',\n",
    "        size='model',\n",
    "        sizes=[1.5, 1, 1],\n",
    "        palette='deep',\n",
    "#         linewidth=1.5,\n",
    "#         markers=['o'] * len(MODELS),\n",
    "        marker='o',\n",
    "        markersize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_xticks(list(range(100, 1100, 100)))\n",
    "    ax.set_xticklabels(labels=list(range(100, 1100, 100)))\n",
    "    ax.set_ylim(bottom=5, top=8)\n",
    "    \n",
    "    ax.set_xlabel('Dimensionality')\n",
    "    ax.set_ylabel('Mean MRE')\n",
    "    ax.set_title('Pricing model accuracy - DEVELOP track')\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, [f'pricing model {m}' if m != 'model' else 'model' for m in labels], prop={'size': 8})\n",
    "    \n",
    "    fig.savefig('img/pm012_dev_track_comparison', dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN algorithm result\n",
    "\n",
    "I trained the KNN model by using concatenation of metadata of challenges and document vectors from pm0 as input `X` and actual prize as input `y` and run 10-fold cross validation to assess the model. The mean MRE is rather positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the pricing model 0, which is based on text mining and analogy estimation, the KNN approach has a rather obivious performance boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What next?**\n",
    "\n",
    "1. I've been trying the paragraph vector (`gensim.models.Doc2Vec`) as another approach to the document vector, but the computing resource required is too large, it will take some time.\n",
    "\n",
    "2. Add more meta data dimensions. *\n",
    "\n",
    "3. relation between subtrack and prize\n",
    "  - violin plot\n",
    "  \n",
    "_Size_ and _Workload_ relation\n",
    "\n",
    "raw dataset could be discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4_measure_df = {}\n",
    "for stat in ('mean', 'median'):\n",
    "    with open(os.path.join(os.curdir, 'pricing_model_4', 'measures', f'measure_FF_600D_{stat}.json')) as f:\n",
    "        pm4_measure_df[stat] = pd.read_json(f, orient='records').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4_measure_df['median']['MRE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmre_df.loc[(mmre_df.track == 'develop') & (mmre_df.model == 0) & (mmre_df.dimension == 600)]['mmre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid', {'xtick.bottom': True}):\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=200)\n",
    "    ax = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "    \n",
    "    sns.pointplot(\n",
    "        x=['pricing model 0', 'pricing model 4\\nmean', 'pricing model 4\\nmedian'],\n",
    "        y=[\n",
    "            mmre_df.loc[(mmre_df.track == 'develop') & (mmre_df.model == 0) & (mmre_df.dimension == 600)]['mmre'],\n",
    "            pm4_measure_df['mean']['MRE'].mean(),\n",
    "            pm4_measure_df['median']['MRE'].mean()\n",
    "        ],\n",
    "#         hue=['pricing model 0', 'pricing model 4\\nmean', 'pricing model 4\\nmedian'],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_ylim(bottom=2.8, top=6.3)\n",
    "    ax.set_xticklabels(labels=['pricing model 0', 'pricing model 4\\nmean', 'pricing model 4\\nmedian'], rotation=345)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, prop={'size': 8})\n",
    "    \n",
    "    ax.set_xlabel('Pricing Models')\n",
    "    ax.set_ylabel('Mean MRE')\n",
    "    ax.set_title('Pricing Model 4 vs. Pricing Model 0')\n",
    "\n",
    "    \n",
    "#     fig.savefig(os.path.join(os.pardir, os.pardir, 'presentation', 'presentation1', 'pm_model4_result.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4_measure_df['median'].join(topcoder.challenge_basic_info['subtrack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm5_measure_df = {}\n",
    "for i in range(5):\n",
    "    with open(os.path.join(os.curdir, 'pricing_model_5', f'knn_measure_{i}.json')) as f:\n",
    "        pm5_measure_df[i] = pd.read_json(f, orient='records').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['all', 'subtrack', 'number_of_platforms', 'number_of_technologies', 'challenge_duration']\n",
    "y = [df['MRE'].mean() for df in pm5_measure_df.values()]\n",
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.15, 0.8, 0.7])\n",
    "    \n",
    "    sns.scatterplot(x=x, y=y, hue=x, ax=ax)\n",
    "    \n",
    "    ax.set_ylim(bottom=2, top=5)\n",
    "    ax.set_xticklabels(labels=['\\n'.join([w for w in i.split('_')]) for i in x])\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, prop={'size': 8})\n",
    "    \n",
    "    ax.set_xlabel('Meta Data vector dimension')\n",
    "    ax.set_ylabel('Mean MRE')\n",
    "    ax.set_title('Pricing Model 5 - differ by metadata vector')\n",
    "    \n",
    "#     fig.savefig(os.path.join(os.pardir, os.pardir, 'presentation', 'presentation1', 'pm_model5_result.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm5_all_meta = [2.747983620506332,\n",
    "                0.8679247258002492,\n",
    "                2.94423992727525,\n",
    "                1.2936881883309923,\n",
    "                9.79137191234242,\n",
    "                1.0955334873771945,\n",
    "                2.05885069744948,\n",
    "                6.948144116625358,\n",
    "                2.599887111152642,\n",
    "                2.34076405590421]\n",
    "    \n",
    "pm5_num_of_platf = [2.9695864514871535,\n",
    " 0.9944216435736005,\n",
    " 3.00411338714871,\n",
    " 1.3694908578836618,\n",
    " 9.814171321044233,\n",
    " 1.4956205818841666,\n",
    " 2.1198146424054984,\n",
    " 17.871945913234256,\n",
    " 2.509684526313345,\n",
    " 2.114763646154109]\n",
    "\n",
    "mmre_by_fold = pd.DataFrame({'challenge_duration': pm5_all_meta, 'num_of_platform': pm5_num_of_platf}).melt()\n",
    "mmre_by_fold.columns = ['meta', 'mmre']\n",
    "mmre_by_fold['fold'] = list(range(10)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=mmre_by_fold,\n",
    "        x='fold',\n",
    "        y='mmre',\n",
    "        hue='meta',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_xticks(list(range(10)))\n",
    "    ax.set_xlabel('nth fold training')\n",
    "    ax.set_ylabel('Mean MRE')\n",
    "    \n",
    "    ax.set_title('Mean MRE by fold')\n",
    "\n",
    "#     fig.savefig(os.path.join(os.pardir, os.pardir, 'presentation', 'presentation1', 'pm_model5_result_by_fold.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Analysis)",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
