{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This notebook will be the formal to train, analyze the word embedding data\n",
    "    (with some ugly code temperately existed of course - but will be cleaned eventually!)\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tc_corpus import TopCoderCorpus\n",
    "from tc_pricing_models import train_word2vec_model, reduce_wv_dimensions, plot_word2vec, cosine_similarity, doc_vector_from_word_vectors\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "TRAINED_WV_PATH = os.path.join(os.curdir, 'models', 'model_20200510T145859')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topcoder_corpus = TopCoderCorpus('detail_requirements.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment following line if training a new model\n",
    "# trained_wv = train_word2vec_model(sentences=topcoder_corpus.get_challenge_req_sentences())\n",
    "\n",
    "# Un-comment following line if using a trained model\n",
    "trained_wv = KeyedVectors.load(TRAINED_WV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of 2-element combinations of `cha_vec_dct` with replacement is 25336521, each execution of `cosine_similarity` takes 15.3 µs ± 1.74 µs (`timeit` with 100 runs and 10000 loops per run). To calculate all cosine similarity for every pair of documents that's stored in a default dict\n",
    "\n",
    "```python\n",
    "cha_cos_sim_matrix = defaultdict(dict)\n",
    "for cha_a, cha_b in itertools.combinations_with_replacement(cha_vec_dct.keys(), 2):\n",
    "    cha_cos_sim_matrix[cha_a][cha_b] = cha_cos_sim_matrix[cha_b][cha_a] = cosine_similarity(cha_vec_dct[cha_a], cha_vec_dct[cha_b])\n",
    "```\n",
    "\n",
    "it takes sometime between 380 and 390 seconds\n",
    "      \n",
    "Whereas the DOK format dict for cosine similarity\n",
    "\n",
    "```python\n",
    "cha_cos_sim_dok = {\n",
    "    (cha_a, cha_b): cosine_similarity(cha_vec_dct[cha_a], cha_vec_dct[cha_b])\n",
    "    for cha_a, cha_b in itertools.combinations_with_replacement(cha_vec_dct.keys(), 2)\n",
    "}\n",
    "```\n",
    "\n",
    "takes 360 seconds.\n",
    "\n",
    "## **Every second counts** ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the vector representation of each challenge, store it in a dictionary\n",
    "challenge_req = topcoder_corpus.get_challenge_req_sentences(as_dataframe=True)\n",
    "cha_vec_dct = {cha_id: doc_vector_from_word_vectors(cha['requirements'], trained_wv) for cha_id, cha in challenge_req.to_dict(orient='index').items()}\n",
    "\n",
    "# calculate cosine similarity for every pair of challenges, sotre it in a DOK format dictionary\n",
    "cha_cos_sim_dok = {\n",
    "    (cha_a, cha_b): cosine_similarity(cha_vec_dct[cha_a], cha_vec_dct[cha_b])\n",
    "    for cha_a, cha_b in itertools.combinations_with_replacement(cha_vec_dct.keys(), 2)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing model 0\n",
    "\n",
    "Base on text mining and analogy estimation approach\n",
    "\n",
    "- ✅ calculate Document2Vector of challenges\n",
    "- ✅ calculate similarity between each pair of challenges\n",
    "- for each task\n",
    "  1. select 10 most similar tasks\n",
    "  2. pricing strategies:\n",
    "      - use average prize of 10 tasks as estimate prize of given\n",
    "      - use mid prize of ...\n",
    "  3. calculate estimation error (MRE magnitude of relative error) based on actual prize\n",
    "  4. repeat\n",
    "- on the entrie dataset, calculate mean MRE -> See how big is it, **this is the measure of accuraccy of the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing model 1\n",
    "\n",
    "Once we get the MRE of all task, we can use any machine learning tech to analyze the error. e.g logistic regression\n",
    "\n",
    "each ML approach produce one model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing model 2\n",
    "\n",
    "Take the meta data of challenges/projects into consideration\n",
    "\n",
    "- Types of challenges (aggregation & sub-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "> Nice to have application  \n",
    "> Not only give a estimated price, but also reasons realted to recommended prize considerin the dynamic context.\n",
    "\n",
    "Take a specific vector space, encode the hidden context, find the hidden factors of uncertainty of a given challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_lst = ['java', 'python', 'javascript', 'php', 'mysql', 'api', 'design', 'prototype', 'ui', 'data', 'science']\n",
    "wv_2D = reduce_wv_dimensions(trained_wv)\n",
    "\n",
    "plot_word2vec(wv_2D, label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python37764bitvenvvenv5b62939097214b20b0ca6487fffe5cee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
